{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\nimport cv2\nimport glob\nfrom torchvision.io import read_image\nfrom clearml import Task, logger\nfrom torchvision.transforms import ToTensor, Compose, Normalize\nimport numpy as np\nfrom datetime import datetime\n\nfrom torchvision import models\nimport time\nimport copy\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\n\n\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\nimport gc\n\nfrom clearml import Task, Logger, Dataset\n#clearml keys should be here","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-29T13:49:53.838986Z","iopub.execute_input":"2023-03-29T13:49:53.839394Z","iopub.status.idle":"2023-03-29T13:49:57.778886Z","shell.execute_reply.started":"2023-03-29T13:49:53.839352Z","shell.execute_reply":"2023-03-29T13:49:57.777866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download dataset from ClearML\n# dataset_name='Dataset_phones_splited_v1' \n# dataset_project='Check in car'\n# dataset_path = Dataset.get(\n#     dataset_name=dataset_name, \n#     dataset_project=dataset_project\n# ).get_local_copy()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T13:57:19.688300Z","iopub.execute_input":"2023-03-29T13:57:19.689171Z","iopub.status.idle":"2023-03-29T13:57:57.916591Z","shell.execute_reply.started":"2023-03-29T13:57:19.689131Z","shell.execute_reply":"2023-03-29T13:57:57.915458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make task in ClearML \n# task = Task.init(\n#     project_name='Check in car', \n#     task_name='MobileNetV2_cls_v5', \n#     tags=['classification','MobileNetV2', 'StepLR'])\n# logger = task.get_logger()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T13:16:01.910274Z","iopub.execute_input":"2023-03-29T13:16:01.911026Z","iopub.status.idle":"2023-03-29T13:16:01.919557Z","shell.execute_reply.started":"2023-03-29T13:16:01.910987Z","shell.execute_reply":"2023-03-29T13:16:01.918487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Drivers_with_phone_Dataset(Dataset):\n    def __init__(self, img_dir, transform=None, target_transform=None):\n        #         self.img_labels = annotations_file\n        self.img_dir = img_dir\n        file_list = glob.glob(self.img_dir + \"*\")\n        self.data = []\n        for class_path in file_list:\n            class_name = class_path.split(\"/\")[-1]\n            for img_path in glob.glob(class_path + \"/*.jpg\"):\n                self.data.append([img_path, class_name])\n        self.class_map = {\"cellphone\": 1, \"no_cellphone\": 0}\n        self.transform = Compose([ToTensor(), Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n        self.target_transform = target_transform\n        self.img_dim = (640, 480)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, class_name = self.data[idx]\n        img = cv2.imread(img_path)\n        img = cv2.resize(img, self.img_dim)\n        class_id = self.class_map[class_name]\n        class_id = torch.tensor(class_id)\n        if self.transform:\n            img_tensor = self.transform(img)\n\n        return img_tensor, class_id","metadata":{"execution":{"iopub.status.busy":"2023-03-29T13:08:26.785723Z","iopub.execute_input":"2023-03-29T13:08:26.786708Z","iopub.status.idle":"2023-03-29T13:08:26.797920Z","shell.execute_reply.started":"2023-03-29T13:08:26.786669Z","shell.execute_reply":"2023-03-29T13:08:26.796805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(epoch_index, tb_writer):\n    full_batch_loss = 0.\n    total = 0\n    correct = 0\n    total_step = len(train_data_loader)\n\n    for i, data in enumerate(train_data_loader):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n\n        # Adjust learning weights\n        optimizer.step()\n        scheduler.step()\n        \n        # Gather data and report\n        full_batch_loss += float(loss.item())\n        \n        #Acc check\n        _,pred = torch.max(outputs, dim=1)\n\n        correct += torch.sum(pred==labels).item()\n        total += labels.size(0)\n\n        torch.cuda.empty_cache()\n    \n    train_acc_epoch = (100 * correct / total)\n    avg_loss = (full_batch_loss/total_step)\n    del full_batch_loss\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    return avg_loss, train_acc_epoch","metadata":{"execution":{"iopub.status.busy":"2023-03-27T16:22:58.649153Z","iopub.execute_input":"2023-03-27T16:22:58.649603Z","iopub.status.idle":"2023-03-27T16:22:58.661098Z","shell.execute_reply.started":"2023-03-27T16:22:58.649564Z","shell.execute_reply":"2023-03-27T16:22:58.659520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Const\nn_epochs = 10\nbatch_size = 32\nlr = 0.001\nbest_vloss = np.Inf\nval_loss = []\nval_acc = []\ntrain_loss = []\ntrain_acc = []\n\n# Download data for testing and training\ndrivers_data_train = dataset_path + '/dataset_phones_splited/train/'\ndrivers_data_test= dataset_path + '/dataset_phones_splited/test/'\n\ntrain_data = Drivers_with_phone_Dataset(drivers_data_train)\ntest_data = Drivers_with_phone_Dataset(drivers_data_test)\n\nprint(len(train_data), len(test_data))\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_data_loader = DataLoader(train_data, batch_size=batch_size,\n                           shuffle=True, num_workers=0)\ntest_data_loader = DataLoader(test_data, batch_size=batch_size,\n                          shuffle=False, num_workers=0)\n\n \n\n\nfor features, labels in train_data_loader:\n    print(\"Shape of batch of features:        \", features.shape)\n    print(\"Shape of the corresponding labels: \", labels.shape)\n    break\n\n# Model, optomizer, loss function\nmodel = models.mobilenet_v2(pretrained=False)\nn = model.classifier[1].in_features\nmodel.classifier = nn.Linear(n, 2)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr)\nscheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\nwriter = SummaryWriter('runs/MobileNet_v2_{}'.format(timestamp))\nepoch_number = 0\n\nfor epoch in range(n_epochs):\n    print('EPOCH {}:'.format(epoch_number + 1))\n    \n    torch.cuda.empty_cache()\n    # On gradients\n    model.train(True)\n    avg_loss, train_acc_epoch = train_one_epoch(epoch_number, writer)\n\n    # Off gradients\n    model.train(False)\n    torch.cuda.empty_cache()\n    \n    with torch.no_grad():\n        print(\"Validation phase\")\n        running_vloss = 0.0\n        total_v = 0\n        correct_v = 0\n        for i, vdata in enumerate(test_data_loader):\n            vinputs, vlabels = vdata\n            vinputs, vlabels = vinputs.to(device), vlabels.to(device) \n            voutputs = model(vinputs)\n            vloss = criterion(voutputs, vlabels)\n            running_vloss += float(vloss.item())\n\n            _,pred_v = torch.max(voutputs, dim=1)\n            correct_v += torch.sum(pred_v==vlabels).item()\n            total_v += vlabels.size(0)\n            torch.cuda.empty_cache()\n\n    avg_vloss = running_vloss / len(test_data_loader)\n    val_acc_epoch = (100 * correct_v / total_v)\n    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n    print(\"ACC train {} valid {}\".format(train_acc_epoch, val_acc_epoch))\n    \n    del running_vloss\n    gc.collect()\n    \n    # Metrics\n    train_loss.append(avg_loss)\n    val_loss.append(float(avg_vloss))\n    train_acc.append(train_acc_epoch)\n    val_acc.append(val_acc_epoch)\n    \n    # When Kaggle is down\n#     json.dump(train_loss, open(\"train_loss.json\", \"w\"), indent=4)\n#     json.dump(val_loss, open(\"val_loss.json\", \"w\"), indent=4)\n#     json.dump(train_acc, open(\"train_acc.json\", \"w\"), indent=4)\n#     json.dump(val_acc, open(\"val_acc.json\", \"w\"), indent=4)\n    \n    \n    #Log loss and accuracy to Clear ML\n    logger.report_scalar(\n        'Training vs. Validation Loss', \"Training\", iteration=epoch_number + 1, value=avg_loss\n    )\n    logger.report_scalar(\n        'Training vs. Validation Loss', \"Validation\", iteration=epoch_number + 1, value=avg_vloss\n    )\n    logger.report_scalar(\n        'Training vs. Validation Accuracy', \"Training\", iteration=epoch_number + 1, value=train_acc_epoch\n    )\n    logger.report_scalar(\n        'Training vs. Validation Accuracy', \"Validation\", iteration=epoch_number + 1, value=val_acc_epoch\n    )\n\n    # Track best performance, and save the model's state\n    if avg_vloss < best_vloss:\n        best_vloss = avg_vloss\n        model_path = 'model_{}_{}'.format(timestamp, \"best\")\n        torch.save(model.state_dict(), model_path)\n\n    epoch_number += 1","metadata":{"execution":{"iopub.status.busy":"2023-03-27T16:24:36.300998Z","iopub.execute_input":"2023-03-27T16:24:36.301506Z","iopub.status.idle":"2023-03-27T16:27:04.109455Z","shell.execute_reply.started":"2023-03-27T16:24:36.301465Z","shell.execute_reply":"2023-03-27T16:27:04.105001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test, Confusion Matrix, ROC-AUC","metadata":{}},{"cell_type":"code","source":"# # Code To Test Pretrained Model\n\n# drivers_data_test= \"/kaggle/input/dataset-phones-splited/dataset_phones_splited/test/\"\n# test_data = Drivers_with_phone_Dataset(drivers_data_test)\n# test_data_loader = DataLoader(test_data, batch_size=32,\n#                           shuffle=False, num_workers=0)\n\n# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# model = models.mobilenet_v2()\n# n = model.classifier[1].in_features\n# model.classifier = nn.Linear(n, 2)\n# model = model.to(device)\n# model.load_state_dict(torch.load(\"/kaggle/input/model-resnet/model_20230328_082109_best\"))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T13:09:35.709537Z","iopub.execute_input":"2023-03-29T13:09:35.709914Z","iopub.status.idle":"2023-03-29T13:09:44.326240Z","shell.execute_reply.started":"2023-03-29T13:09:35.709881Z","shell.execute_reply":"2023-03-29T13:09:44.325191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Model\n\ny_pred_list = []\ny_test = []\ny_pred_proba = []\nwith torch.no_grad():\n    model.eval()\n    for X_batch, y_batch in test_data_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        _, y_pred_tags = torch.max(y_test_pred, dim = 1)\n        y_pred_list.append(y_pred_tags.cpu().numpy())\n        y_test.append(y_batch.cpu().numpy())\n        y_pred_proba.append(y_test_pred)\n        \n# for conf matr and roc\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]\ny_test = [a.squeeze().tolist() for a in y_test]\n\n# one big list\ny_pred_list_flat = [item for sublist in y_pred_list for item in sublist]\ny_test_flat = [item for sublist in y_test for item in sublist]","metadata":{"execution":{"iopub.status.busy":"2023-03-29T13:10:38.582642Z","iopub.execute_input":"2023-03-29T13:10:38.583577Z","iopub.status.idle":"2023-03-29T13:12:03.543311Z","shell.execute_reply.started":"2023-03-29T13:10:38.583538Z","shell.execute_reply":"2023-03-29T13:12:03.542230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calc Confusion matrix and log to Clear ML\nconfusion_matrix_1 = confusion_matrix(y_test_flat, y_pred_list_flat)\n\nlogger.report_matrix(\n    \"Confusion_matrix_\",\n    \"ignored\",\n    matrix=confusion_matrix_1,\n    xaxis=\"Predicted lable\",\n    yaxis=\"True label\",\n    xlabels= [\"no phones\", \"phone\"],\n    ylabels=  [\"no phones\", \"phone\"],\n    yaxis_reversed=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T13:12:03.554169Z","iopub.execute_input":"2023-03-29T13:12:03.555392Z","iopub.status.idle":"2023-03-29T13:12:03.581397Z","shell.execute_reply.started":"2023-03-29T13:12:03.555323Z","shell.execute_reply":"2023-03-29T13:12:03.580293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calc Roc-Auc \nfpr, tpr, thresholds = roc_curve(y_test_flat, y_pred_list_flat)\nauc = roc_auc_score(y_test_flat, y_pred_list_flat)\nlogger.report_scatter2d(\n    \"ROC AUC Curve\",\n    \"ROC\",\n    scatter=zip(fpr,tpr),\n    yaxis=\"tpr\",\n    xaxis=\"fpr\",\n    mode='lines+markers'\n)\nlogger.flush()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T13:24:06.800296Z","iopub.execute_input":"2023-03-29T13:24:06.800964Z","iopub.status.idle":"2023-03-29T13:24:06.815189Z","shell.execute_reply.started":"2023-03-29T13:24:06.800926Z","shell.execute_reply":"2023-03-29T13:24:06.814246Z"},"trusted":true},"execution_count":null,"outputs":[]}]}